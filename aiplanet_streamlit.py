# -*- coding: utf-8 -*-
"""AIPlanet_Streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zFgTynTe_CAmTIrMUV0iL5OWAdOYbedw
"""

def predict(image, caption):
    inputs = processor(text=[caption], images=[image], return_tensors="pt", padding=True, truncation=True)
    outputs = model(**inputs)
    logits_per_image = outputs.logits_per_image
    logits_per_text = outputs.logits_per_text
    return {
        'logits_per_image': logits_per_image.tolist(),
        'logits_per_text': logits_per_text.tolist(),
    }

st.title("CLIP Model Fine-tuning and Prediction")

uploaded_image = st.file_uploader("Upload an image...", type=["jpg", "jpeg", "png"])
caption = st.text_input("Enter a caption for the image:")

if uploaded_image is not None and caption:
    image = Image.open(uploaded_image)
    st.image(image, caption="Uploaded Image", use_column_width=True)

    # Make prediction
    if st.button("Predict"):
        prediction = predict(image, caption)
        st.write("Logits per Image:", prediction['logits_per_image'])
        st.write("Logits per Text:", prediction['logits_per_text'])

# Sidebar with training information
st.sidebar.title("Training Information")
st.sidebar.write("Training Loss:")
st.sidebar.write("Validation Loss:")